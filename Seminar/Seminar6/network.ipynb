{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Regression_BSD_hour(1).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(instant       0\n",
       " dteday        0\n",
       " season        0\n",
       " yr            0\n",
       " mnth          0\n",
       " hr            0\n",
       " holiday       0\n",
       " weekday       0\n",
       " workingday    0\n",
       " weathersit    0\n",
       " temp          0\n",
       " atemp         0\n",
       " hum           0\n",
       " windspeed     0\n",
       " casual        0\n",
       " registered    0\n",
       " cnt           0\n",
       " dtype: int64,\n",
       " count    17379.000000\n",
       " mean       189.463088\n",
       " std        181.387599\n",
       " min          1.000000\n",
       " 25%         40.000000\n",
       " 50%        142.000000\n",
       " 75%        281.000000\n",
       " max        977.000000\n",
       " Name: cnt, dtype: float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = data.isnull().sum()\n",
    "\n",
    "cnt_distribution = data['cnt'].describe()\n",
    "\n",
    "missing_values, cnt_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13903, 61), (3476, 61))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Features and target variable\n",
    "X = data.drop(['instant', 'dteday', 'casual', 'registered', 'cnt'], axis=1)\n",
    "y = data['cnt']\n",
    "\n",
    "# Identifying numerical and categorical columns\n",
    "numerical_cols = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "categorical_cols = ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "\n",
    "# Creating a preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit and transform the training data and transform the test data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "X_train_preprocessed.shape, X_test_preprocessed.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 10:54:12.010222: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - ETA: 0s - loss: 38897.2695 - mae: 135.7346"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 10:54:14.274380: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 3s 6ms/step - loss: 38897.2695 - mae: 135.7346 - val_loss: 17791.7461 - val_mae: 95.3461\n",
      "Epoch 2/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 13525.0430 - mae: 84.8332 - val_loss: 11719.0107 - val_mae: 80.4599\n",
      "Epoch 3/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 11047.6104 - mae: 78.3590 - val_loss: 12363.2061 - val_mae: 83.6365\n",
      "Epoch 4/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 11415.0791 - mae: 79.9112 - val_loss: 12304.1182 - val_mae: 83.9547\n",
      "Epoch 5/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 11299.4824 - mae: 79.0117 - val_loss: 12107.6592 - val_mae: 83.0546\n",
      "Epoch 6/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 11051.8711 - mae: 78.0681 - val_loss: 11685.6719 - val_mae: 81.3352\n",
      "Epoch 7/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10835.4541 - mae: 77.2142 - val_loss: 11569.7812 - val_mae: 79.5086\n",
      "Epoch 8/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 10776.9316 - mae: 77.0770 - val_loss: 11417.3828 - val_mae: 79.5174\n",
      "Epoch 9/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 10726.8486 - mae: 77.1875 - val_loss: 11477.9805 - val_mae: 80.9907\n",
      "Epoch 10/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 10706.5146 - mae: 77.2583 - val_loss: 11420.7471 - val_mae: 80.9661\n",
      "Epoch 11/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 10712.2051 - mae: 77.3358 - val_loss: 11674.9258 - val_mae: 79.7197\n",
      "Epoch 12/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 10779.3662 - mae: 77.6921 - val_loss: 11541.0508 - val_mae: 79.8647\n",
      "Epoch 13/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10812.1064 - mae: 78.0205 - val_loss: 11445.7080 - val_mae: 79.2586\n",
      "Epoch 14/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 10845.4570 - mae: 77.9069 - val_loss: 11652.5137 - val_mae: 80.6515\n",
      "Epoch 15/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10774.0176 - mae: 77.5020 - val_loss: 11779.8906 - val_mae: 80.5399\n",
      "Epoch 16/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10764.3936 - mae: 77.6392 - val_loss: 11499.6855 - val_mae: 81.3663\n",
      "Epoch 17/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10777.4189 - mae: 77.4971 - val_loss: 11367.8350 - val_mae: 81.7971\n",
      "Epoch 18/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 10791.5928 - mae: 77.4796 - val_loss: 11506.8887 - val_mae: 77.9861\n",
      "Epoch 19/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 10775.6855 - mae: 77.4744 - val_loss: 12046.1230 - val_mae: 80.3997\n",
      "Epoch 20/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10743.8750 - mae: 77.4440 - val_loss: 11325.5264 - val_mae: 79.3371\n",
      "Epoch 21/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10880.2314 - mae: 77.9168 - val_loss: 11987.8418 - val_mae: 79.1322\n",
      "Epoch 22/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10764.4971 - mae: 77.5528 - val_loss: 11704.3252 - val_mae: 78.1026\n",
      "Epoch 23/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10802.7451 - mae: 77.6280 - val_loss: 12604.9307 - val_mae: 80.9479\n",
      "Epoch 24/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 10912.5547 - mae: 78.2968 - val_loss: 11467.1250 - val_mae: 82.9298\n",
      "Epoch 25/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10816.7373 - mae: 78.0187 - val_loss: 12336.3652 - val_mae: 84.4719\n",
      "Epoch 26/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 10961.4404 - mae: 78.2849 - val_loss: 13444.6846 - val_mae: 80.9608\n",
      "Epoch 27/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 10971.1240 - mae: 78.5316 - val_loss: 11309.7266 - val_mae: 81.2214\n",
      "Epoch 28/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 10920.1436 - mae: 78.3027 - val_loss: 11696.2842 - val_mae: 81.6942\n",
      "Epoch 29/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 10968.9600 - mae: 78.5768 - val_loss: 11518.1562 - val_mae: 83.3946\n",
      "Epoch 30/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 10844.0879 - mae: 78.1699 - val_loss: 11442.8818 - val_mae: 79.5909\n",
      "Epoch 31/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 11078.9443 - mae: 78.8270 - val_loss: 11208.1816 - val_mae: 80.2341\n",
      "Epoch 32/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 11111.1807 - mae: 79.2194 - val_loss: 11173.7705 - val_mae: 78.5879\n",
      "Epoch 33/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 11173.9355 - mae: 79.1256 - val_loss: 13250.0225 - val_mae: 92.3142\n",
      "Epoch 34/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 11271.2773 - mae: 79.7647 - val_loss: 13287.2666 - val_mae: 81.3798\n",
      "Epoch 35/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 11149.8242 - mae: 79.3023 - val_loss: 12278.9355 - val_mae: 80.8441\n",
      "Epoch 36/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 11164.3604 - mae: 79.4150 - val_loss: 11852.9883 - val_mae: 78.8361\n",
      "Epoch 37/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 11495.7178 - mae: 80.6095 - val_loss: 11618.4902 - val_mae: 83.1600\n",
      "Epoch 38/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 11472.5215 - mae: 80.8620 - val_loss: 11728.3838 - val_mae: 84.1249\n",
      "Epoch 39/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 11613.1992 - mae: 80.8805 - val_loss: 11493.7686 - val_mae: 82.1639\n",
      "Epoch 40/100\n",
      "242/348 [===================>..........] - ETA: 0s - loss: 11253.5400 - mae: 79.4079"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m X_test_preprocessed_dense \u001b[38;5;241m=\u001b[39m X_test_preprocessed\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Now, use the dense arrays for training and evaluation\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_preprocessed_dense\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the dense test set\u001b[39;00m\n\u001b[1;32m     23\u001b[0m test_loss, test_mae \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test_preprocessed_dense, y_test)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensyflow/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensyflow/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensyflow/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensyflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensyflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensyflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensyflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensyflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/envs/tensyflow/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensyflow/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_preprocessed.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "X_train_preprocessed_dense = X_train_preprocessed.toarray()\n",
    "X_test_preprocessed_dense = X_test_preprocessed.toarray()\n",
    "\n",
    "history = model.fit(X_train_preprocessed_dense, y_train, validation_split=0.2, epochs=100, batch_size=32)\n",
    "\n",
    "test_loss, test_mae = model.evaluate(X_test_preprocessed_dense, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data\n",
      "[[-1.54083688 -1.62031134 -0.3994488  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.1171121   0.13822833 -1.07374273 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.19375333 -0.12584281  1.93464557 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 1.56781745  1.45742327 -1.02187397 ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.33359326 -1.62031134  0.11923884 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.1171121   0.13822833  1.05287659 ...  1.          0.\n",
      "   0.        ]] [[ 1.56781745  1.2815693  -1.85177419 ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.33359326 -1.44445738 -1.1256115  ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.91910601 -1.00511265  0.1711076  ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-1.54083688 -1.70852852 -0.19197375 ...  1.          0.\n",
      "   0.        ]\n",
      " [-0.09013152 -0.03762564  0.741664   ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.91910601 -0.91689548 -0.71066138 ...  0.          0.\n",
      "   0.        ]]\n",
      "Build the model\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_63 (Dense)            (None, 64)                3968      \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6081 (23.75 KB)\n",
      "Trainable params: 6081 (23.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training the model\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 11:45:19.259901: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - ETA: 0s - loss: 37111.5273 - mae: 133.9088 - rmse: 184.8723"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 11:45:21.542824: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 3s 7ms/step - loss: 37111.5273 - mae: 133.9088 - rmse: 184.8723 - val_loss: 17881.2598 - val_mae: 98.0976 - val_rmse: 131.3700 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 14210.7500 - mae: 87.8656 - rmse: 117.1516 - val_loss: 12450.7705 - val_mae: 85.0263 - val_rmse: 110.1525 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 11739.5889 - mae: 82.3969 - rmse: 107.1132 - val_loss: 12415.0469 - val_mae: 85.5434 - val_rmse: 110.2113 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 11788.3066 - mae: 83.2000 - rmse: 107.4107 - val_loss: 12332.2451 - val_mae: 85.9670 - val_rmse: 109.9064 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 11510.0410 - mae: 82.5395 - rmse: 105.9885 - val_loss: 11880.5010 - val_mae: 84.6553 - val_rmse: 107.8432 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 11147.4863 - mae: 81.1190 - rmse: 104.5027 - val_loss: 11701.8154 - val_mae: 84.2137 - val_rmse: 107.1075 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10909.0684 - mae: 79.6655 - rmse: 103.3662 - val_loss: 11449.7705 - val_mae: 81.0590 - val_rmse: 105.7671 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10740.8389 - mae: 78.4177 - rmse: 102.4581 - val_loss: 11374.8760 - val_mae: 80.2949 - val_rmse: 105.3684 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10714.3584 - mae: 77.6815 - rmse: 101.9360 - val_loss: 11348.2021 - val_mae: 79.1181 - val_rmse: 105.1026 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10676.9287 - mae: 77.3911 - rmse: 101.9476 - val_loss: 11285.0146 - val_mae: 79.7183 - val_rmse: 104.9409 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10674.4961 - mae: 77.2540 - rmse: 101.9271 - val_loss: 11582.8184 - val_mae: 82.7128 - val_rmse: 106.5445 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10705.1416 - mae: 77.2039 - rmse: 102.1075 - val_loss: 11538.2197 - val_mae: 82.0158 - val_rmse: 106.2907 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10724.9580 - mae: 77.4962 - rmse: 102.1337 - val_loss: 11416.1240 - val_mae: 80.5646 - val_rmse: 105.6264 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10732.8057 - mae: 77.6776 - rmse: 102.1095 - val_loss: 11696.7344 - val_mae: 80.9556 - val_rmse: 106.9179 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "342/348 [============================>.] - ETA: 0s - loss: 10777.7979 - mae: 77.8245 - rmse: 102.3798\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10791.5879 - mae: 77.8742 - rmse: 102.4847 - val_loss: 11794.9424 - val_mae: 80.3571 - val_rmse: 107.3005 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10699.4561 - mae: 77.4955 - rmse: 102.1712 - val_loss: 11390.8047 - val_mae: 79.0650 - val_rmse: 105.3341 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10689.8428 - mae: 77.5136 - rmse: 102.1234 - val_loss: 11353.2539 - val_mae: 80.1887 - val_rmse: 105.2394 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10719.9541 - mae: 77.4287 - rmse: 102.0291 - val_loss: 11525.4180 - val_mae: 80.3654 - val_rmse: 106.0892 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10719.5000 - mae: 77.5228 - rmse: 102.1823 - val_loss: 11545.2520 - val_mae: 78.4632 - val_rmse: 105.9711 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "343/348 [============================>.] - ETA: 0s - loss: 10664.3779 - mae: 77.2169 - rmse: 101.8442\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 10709.4277 - mae: 77.3851 - rmse: 102.1103 - val_loss: 11526.0078 - val_mae: 81.2570 - val_rmse: 106.1528 - lr: 5.0000e-04\n",
      "Epoch 20: early stopping\n",
      "Plot the model\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate model\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 10576.9160 - mae: 77.2761 - rmse: 101.5319\n",
      "Test Loss: 10576.916015625, Test MAE: 77.276123046875, Test RMSE: 101.53185272216797\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "import keras.backend as K\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def load_and_preprocess_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "\n",
    "    X = data.drop(['instant', 'dteday', 'casual', 'registered', 'cnt'], axis=1)\n",
    "    y = data['cnt']\n",
    "    \n",
    "    numerical_cols = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "    categorical_cols = ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "    \n",
    "    # Creating a preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_cols),\n",
    "            ('cat', OneHotEncoder(), categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_test_preprocessed = preprocessor.transform(X_test)\n",
    "    \n",
    "    X_train_preprocessed = X_train_preprocessed.toarray()\n",
    "    X_test_preprocessed = X_test_preprocessed.toarray()\n",
    "\n",
    "    print(X_train_preprocessed, X_test_preprocessed)\n",
    "    \n",
    "    return X_train_preprocessed, X_test_preprocessed, y_train, y_test\n",
    "\n",
    "\n",
    "# def build_model(input_shape):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(128, activation='relu', input_shape=(input_shape,)))\n",
    "#     # model.add(Dense(128, activation='relu', input_shape=(input_shape,), kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)))\n",
    "\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.3))\n",
    "    \n",
    "#     # model.add(Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)))\n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.3))\n",
    "\n",
    "#     model.add(Dense(64, activation='relu'))    \n",
    "#     # model.add(Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.2))\n",
    "\n",
    "#     model.add(Dense(32, activation='relu'))    \n",
    "#     # model.add(Dense(32, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.1))\n",
    "    \n",
    "#     model.add(Dense(1)) \n",
    "    \n",
    "#     optimizer = Adam(learning_rate=0.001)\n",
    "#     model.compile(optimizer=optimizer, loss='mse', metrics=['mae', rmse])\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(input_shape,)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer for regression\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    # Include RMSE in the metrics\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae', rmse])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "    \n",
    "    return model\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='validation')\n",
    "    plt.title('Model Loss Progress')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    print(\"Load data\")\n",
    "    filepath = 'Regression_BSD_hour(1).csv'  # Update this path\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data(filepath)\n",
    "    \n",
    "    print(\"Build the model\")\n",
    "    model = build_model(X_train.shape[1])\n",
    "    print(model.summary())\n",
    "    \n",
    "    print(\"Training the model\") \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n",
    "    history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, callbacks=[early_stopping, reduce_lr], batch_size=32, verbose=1)\n",
    "    \n",
    "    print(\"Plot the model\")\n",
    "    plot_history(history)\n",
    "    \n",
    "    print(\"Evaluate model\")\n",
    "    test_loss, test_mae, test_rmse = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f'Test Loss: {test_loss}, Test MAE: {test_mae}, Test RMSE: {test_rmse}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensyflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
